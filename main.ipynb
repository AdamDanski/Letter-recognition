{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Projekt: Rozpoznanie liter\n",
        "\n",
        "## Opis zadania\n",
        "Celem jest klasyfikacja 20 000 liter na podstawie 16 atrybutów numerycznych. Pierwsza kolumna pliku `letter-recognition.data` zawiera etykietę (literę), a kolejne 16 kolumn to cechy.\n",
        "\n",
        "## Metoda\n",
        "- Normalizacja cech do zakresu (0, 1) przy użyciu `MinMaxScaler`.\n",
        "- Sztywny podział danych bez mieszania: pierwsze 16 000 próbek do treningu, pozostałe 4 000 do testu.\n",
        "- Modele: k-NN oraz Gaussian Naive Bayes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Instalacja bibliotek\n",
        "Rekomendowane jest własne środowisko (venv), żeby uniknąć błędu PEP 668:\n",
        "\n",
        "```\n",
        "python3 -m venv .venv\n",
        "source .venv/bin/activate\n",
        "python3 -m pip install --upgrade pip\n",
        "python3 -m pip install pandas scikit-learn\n",
        "```\n",
        "\n",
        "Po instalacji wybierz kernel z `.venv` w Jupyter.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Szybka weryfikacja środowiska (uruchom po instalacji)\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "try:\n",
        "    import sklearn  # noqa: F401\n",
        "except ModuleNotFoundError:\n",
        "    subprocess.check_call(\n",
        "        [\n",
        "            sys.executable,\n",
        "            \"-m\",\n",
        "            \"pip\",\n",
        "            \"install\",\n",
        "            \"pandas\",\n",
        "            \"scikit-learn\",\n",
        "        ]\n",
        "    )\n",
        "    import sklearn  # noqa: F401\n",
        "\n",
        "print(\"OK: scikit-learn jest dostępny w kernelu:\", sys.executable)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.14.2' requires the ipykernel package.\n",
            "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
            "\u001b[1;31mOr install 'ipykernel' using the command: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Wczytanie danych bez nagłówka\n",
        "# Pierwsza kolumna: etykieta, kolejne 16: cechy\n",
        "\n",
        "data = pd.read_csv(\n",
        "    \"/Users/mateuszgorka/Downloads/letter+recognition/letter-recognition.data\",\n",
        "    header=None,\n",
        ")\n",
        "\n",
        "y = data.iloc[:, 0]\n",
        "X = data.iloc[:, 1:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normalizacja cech do (0, 1)\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Sztywny podział: 16 000 trening, 4 000 test\n",
        "X_train, X_test = X_scaled[:16000], X_scaled[16000:]\n",
        "y_train, y_test = y.iloc[:16000], y.iloc[16000:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Widoczny podział na zbiory\n",
        "print(\"X_train:\", X_train.shape, \"y_train:\", y_train.shape)\n",
        "print(\"X_test:\", X_test.shape, \"y_test:\", y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Porównanie kilku ustawień k-NN\n",
        "knn_results = []\n",
        "\n",
        "for n_neighbors in [1, 3, 5, 7, 9, 11]:\n",
        "    for weights in [\"uniform\", \"distance\"]:\n",
        "        for metric in [\"euclidean\", \"manhattan\"]:\n",
        "            model = KNeighborsClassifier(\n",
        "                n_neighbors=n_neighbors,\n",
        "                weights=weights,\n",
        "                metric=metric,\n",
        "            )\n",
        "            model.fit(X_train, y_train)\n",
        "            preds = model.predict(X_test)\n",
        "            acc = accuracy_score(y_test, preds)\n",
        "            knn_results.append(\n",
        "                {\n",
        "                    \"Model\": \"k-NN\",\n",
        "                    \"Parametry\": f\"k={n_neighbors}, wagi={weights}, metryka={metric}\",\n",
        "                    \"Accuracy\": acc,\n",
        "                }\n",
        "            )\n",
        "\n",
        "# Porównanie kilku ustawień GaussianNB\n",
        "nb_results = []\n",
        "\n",
        "for var_smoothing in [1e-9, 1e-8, 1e-7, 1e-6, 1e-5]:\n",
        "    model = GaussianNB(var_smoothing=var_smoothing)\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, preds)\n",
        "    nb_results.append(\n",
        "        {\n",
        "            \"Model\": \"Naive Bayes\",\n",
        "            \"Parametry\": f\"var_smoothing={var_smoothing:g}\",\n",
        "            \"Accuracy\": acc,\n",
        "        }\n",
        "    )\n",
        "\n",
        "knn_results_df = pd.DataFrame(knn_results).sort_values(\n",
        "    by=\"Accuracy\", ascending=False\n",
        ")\n",
        "nb_results_df = pd.DataFrame(nb_results).sort_values(by=\"Accuracy\", ascending=False)\n",
        "\n",
        "best_knn = knn_results_df.iloc[0]\n",
        "best_nb = nb_results_df.iloc[0]\n",
        "\n",
        "best_overall = pd.concat([best_knn.to_frame().T, best_nb.to_frame().T]).sort_values(\n",
        "    by=\"Accuracy\", ascending=False\n",
        ").iloc[0]\n",
        "\n",
        "print(\n",
        "    f\"Najlepszy k-NN: {best_knn['Accuracy']:.4f} ({best_knn['Parametry']})\"\n",
        ")\n",
        "print(\n",
        "    f\"Najlepszy Naive Bayes: {best_nb['Accuracy']:.4f} ({best_nb['Parametry']})\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tabele wyników (top 5 dla każdego modelu)\n",
        "knn_results_df.head(5)\n",
        "\n",
        "nb_results_df.head(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Wnioski: najlepsze ustawienie dla każdego modelu i zwycięzca\n",
        "if best_overall[\"Model\"] == \"k-NN\":\n",
        "    better_model = \"k-NN\"\n",
        "else:\n",
        "    better_model = \"Naive Bayes\"\n",
        "\n",
        "print(f\"Lepszy model: {better_model}\")\n",
        "print(\n",
        "    f\"Najlepsze parametry: {best_overall['Parametry']} (Accuracy={best_overall['Accuracy']:.4f})\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Wyniki\n",
        "W tabelach zestawione są różne konfiguracje k-NN i GaussianNB, co pozwala łatwo wychwycić, które ustawienia wypadają najlepiej.\n",
        "\n",
        "## Wnioski\n",
        "Na końcu notatnika pojawia się krótka informacja o najlepszym wariancie oraz zwycięskim modelu na zbiorze testowym.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
